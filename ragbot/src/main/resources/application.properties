# In order to use the EasyRAG extension the only required configuration
# is the input directory, everything else is optional! During startup
# the documents in the directly will be ingested using the configured
# embedding function, and stored in a simple in-memory store, or
# to an embedding store, if one is present, using a simple document
# splitting strategy with some configurable options (max-segment-size,
# max-overlap-size). Those embeddings can also be stored in a local cache
# (easy-rag-embeddings.json) to avoid recalculating them on the next restart.
# A default RetrievalAugmentor will automatically augment calls to the model
# by querying the configured in-process (or remote) embedding store.
#
# More info: https://docs.quarkiverse.io/quarkus-langchain4j/dev/easy-rag.html

### Easy RAG related properties
# Path to the directory to look for documents to ingest
quarkus.langchain4j.easy-rag.path=easy-rag-docs

# recurse into subdirectories, default=true
# quarkus.langchain4j.easy-rag.recursive=true

# Reuse embeddings previously stored in file 'easy-rag-embeddings.json', default=false
quarkus.langchain4j.easy-rag.reuse-embeddings.enabled=true

# Use an in-process embedding model, instead of the remote one provided by the LLM
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallen.BgeSmallEnEmbeddingModel

### Other properties
# Log requests/responses
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
quarkus.langchain4j.openai.timeout=60s